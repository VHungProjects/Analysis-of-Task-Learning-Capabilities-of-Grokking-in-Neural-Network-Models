{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2060'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000.0\n"
     ]
    }
   ],
   "source": [
    "#Set Parameters here\n",
    "epochs = 200000\n",
    "batch_size = 1000\n",
    "train_points = 1000 # 60k total training examples, 10k test examples\n",
    "test_points = 1000\n",
    "lr = 0.001\n",
    "weight_decay = 0.01\n",
    "initialization_scale = 8.0\n",
    "#Optmization steps should be train_points/batchsize * epochs \n",
    "print(train_points/batch_size * epochs)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network Structure\n",
    "class mnistClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mnistClassification, self).__init__()\n",
    "        self.flatten = nn.Flatten().to(device)\n",
    "        self.fc1 = nn.Linear(784, 200).to(device)\n",
    "        self.fc2 = nn.Linear(200, 200).to(device)\n",
    "        self.fc3 = nn.Linear(200, 10).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.nn.functional.softmax(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "model = mnistClassification().to(device)\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for p in model.parameters(): \n",
    "        p.data = initialization_scale * p.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\Allclan\\AppData\\Local\\Temp\\ipykernel_53108\\3445561082.py:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  train = torchvision.datasets.MNIST(root='Data\\mnistdata', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
      "C:\\Users\\Allclan\\AppData\\Local\\Temp\\ipykernel_53108\\3445561082.py:3: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  test = torchvision.datasets.MNIST(root='Data\\mnistdata', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to Data\\mnistdata\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:01<00:00, 6.22MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data\\mnistdata\\MNIST\\raw\\train-images-idx3-ubyte.gz to Data\\mnistdata\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to Data\\mnistdata\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 27.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data\\mnistdata\\MNIST\\raw\\train-labels-idx1-ubyte.gz to Data\\mnistdata\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to Data\\mnistdata\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.94MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data\\mnistdata\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to Data\\mnistdata\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to Data\\mnistdata\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.63MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data\\mnistdata\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to Data\\mnistdata\\MNIST\\raw\n",
      "\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Load Data set\n",
    "train = torchvision.datasets.MNIST(root='mnistdata', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test = torchvision.datasets.MNIST(root='mnistdata', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "train = torch.utils.data.Subset(train, range(train_points))\n",
    "test = torch.utils.data.Subset(test, range(test_points))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200000 [00:00<?, ?it/s]C:\\Users\\Allclan\\AppData\\Local\\Temp\\ipykernel_53108\\368128771.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = torch.nn.functional.softmax(self.fc3(x))\n",
      "Epoch [56/200000], Loss: 0.0686, Train Accuracy: 0.5890, Val Accuracy: 0.5300, Weight Norm: 152.9363:   0%|          | 56/200000 [00:21<15:59:36,  3.47it/s]"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "weight_normlist = []\n",
    "\n",
    "#Loop\n",
    "bar = tqdm(range(epochs))\n",
    "for epoch in bar:\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        labels_one_hot = F.one_hot(labels, 10).float()\n",
    "        loss = criterion(outputs, labels_one_hot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate Train Accuracy\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct_train += (predicted == labels).sum().item()\n",
    "    total_train += labels.size(0)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_acc.append(train_accuracy)\n",
    "    \n",
    "    # Store loss\n",
    "    train_loss.append(loss.item())\n",
    "    \n",
    "    # Calculate Validation Accuracy\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, labels in test_loader:\n",
    "            x = x.to(device)\n",
    "            labels = labels.to(device)\n",
    "            y = model(x)\n",
    "            _, predicted = torch.max(y, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_accuracy = correct / total\n",
    "    val_acc.append(val_accuracy)\n",
    "\n",
    "    # Calculate Weight Norm\n",
    "    weight_norm = sum(p.norm().item() for p in model.parameters())\n",
    "    weight_normlist.append(weight_norm)\n",
    "    \n",
    "    # Print progress\n",
    "    bar.set_description(f'Epoch [{epoch+1}/{epochs}], Loss: {loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}, Weight Norm: {weight_norm:.4f}')\n",
    "    \n",
    "    # Plot graph every 50,000 epochs\n",
    "    if (epoch + 1) % 10000 == 0:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.xscale(\"log\")\n",
    "        plt.plot(range(1, epoch + 2), train_acc, label='Training Accuracy')\n",
    "        plt.plot(range(1, epoch + 2), val_acc, label='Validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Training vs Validation Accuracy')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.20%\n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "one_hots = torch.eye(10, 10)\n",
    "with torch.no_grad():\n",
    "        for x, labels in test_loader:\n",
    "            x = x.to(device)\n",
    "            labels = labels.to(device)\n",
    "            y = model(x)\n",
    "            _, predicted = torch.max(y,1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.20%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to display images and predictions\n",
    "def display_predictions(model, testloader, num_images=5):\n",
    "    model.eval()\n",
    "    images, labels = next(iter(testloader))\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
    "    for i in range(num_images):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(images[i].to(\"cpu\").numpy().squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Pred: {predicted[i].item()}')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "one_hots = torch.eye(10, 10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, labels in test_loader:\n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "        y = model(x)\n",
    "        _, predicted = torch.max(y, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {100 * accuracy:.2f}%')\n",
    "\n",
    "# Display example predictions\n",
    "display_predictions(model, test_loader, num_images=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Training\\n\\ncriterion = nn.MSELoss()\\noptimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\\n\\ntrain_acc = []\\nval_acc = []\\ntrain_loss = []\\nweight_normlist = []\\n\\n#Loop\\nbar = tqdm(range(epochs))\\nfor epoch in bar:\\n    model.train()\\n    running_loss = 0.0\\n    correct_train = 0\\n    total_train = 0\\n    \\n    for images, labels in train_loader:\\n        optimizer.zero_grad()\\n        outputs = model(images)\\n        labels_one_hot = F.one_hot(labels, 10).float()\\n        loss = criterion(outputs, labels_one_hot)\\n        loss.backward()\\n        optimizer.step()\\n        running_loss += loss.item()\\n\\n    #Calculate Train Accuracy\\n    _, predicted = torch.max(outputs.data, 1)\\n    correct_train += (predicted == labels).sum().item()\\n    total_train += labels.size(0)\\n    train_accuracy = correct_train / total_train\\n    train_acc.append(train_accuracy)\\n    #Store loss\\n    train_loss.append(loss)\\n    #Calculate Validation Accuracy\\n    model.eval()\\n    total = 0\\n    correct = 0\\n    one_hots = torch.eye(10, 10)\\n    with torch.no_grad():\\n            for x, labels in test_loader:\\n                y = model(x)\\n                _, predicted = torch.max(y,1)\\n                correct += (predicted == labels).sum().item()\\n                total += labels.size(0)\\n    val_accuracy = correct / total\\n    val_acc.append(val_accuracy)\\n\\n    #Calculate Weight Norm\\n    weight_norm = sum(p.norm().item() for p in model.parameters())\\n    weight_normlist.append(weight_norm)\\n    #print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\\n    bar.set_description(f'Epoch [{epoch+1}/{epochs}], Loss: {loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}, Weight Norm: {weight_norm:.4f}')\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Training\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "weight_normlist = []\n",
    "\n",
    "#Loop\n",
    "bar = tqdm(range(epochs))\n",
    "for epoch in bar:\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        labels_one_hot = F.one_hot(labels, 10).float()\n",
    "        loss = criterion(outputs, labels_one_hot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    #Calculate Train Accuracy\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct_train += (predicted == labels).sum().item()\n",
    "    total_train += labels.size(0)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_acc.append(train_accuracy)\n",
    "    #Store loss\n",
    "    train_loss.append(loss)\n",
    "    #Calculate Validation Accuracy\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    one_hots = torch.eye(10, 10)\n",
    "    with torch.no_grad():\n",
    "            for x, labels in test_loader:\n",
    "                y = model(x)\n",
    "                _, predicted = torch.max(y,1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "    val_accuracy = correct / total\n",
    "    val_acc.append(val_accuracy)\n",
    "\n",
    "    #Calculate Weight Norm\n",
    "    weight_norm = sum(p.norm().item() for p in model.parameters())\n",
    "    weight_normlist.append(weight_norm)\n",
    "    #print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "    bar.set_description(f'Epoch [{epoch+1}/{epochs}], Loss: {loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}, Weight Norm: {weight_norm:.4f}')\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
